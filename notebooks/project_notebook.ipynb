{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "computational-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charitable-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Lab cell extensions\n",
    "%load_ext rpy2.ipython \n",
    "%load_ext memory_profiler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-election",
   "metadata": {},
   "source": [
    "## 3. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figsharedailyrain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "happy-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  \n",
    "files = data[\"files\"]             \n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_dl = [\"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rapid-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-kenya",
   "metadata": {},
   "source": [
    "## 4. Combining data CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-aquatic",
   "metadata": {},
   "source": [
    "### 4.1 & 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "taken-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cognitive-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 164.31 MiB, increment: 0.02 MiB\n",
      "CPU times: user 4min 56s, sys: 7.02 s, total: 5min 3s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "use_cols = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "files = glob.glob('figsharedailyrain/*.csv')\n",
    "files[:] = [x for x in files if \"observed\" not in x]\n",
    "df = pd.DataFrame(columns=use_cols)\n",
    "df = pd.concat((pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "                .assign(model=re.findall(r'[^\\/|\\\\]+(?=\\.)', file.replace('_daily_rainfall_NSW', ''))[0])\n",
    "                for file in files)\n",
    "              )  \n",
    "df.to_csv(\"figsharedailyrain/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accompanied-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigsharedailyrain/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figsharedailyrain/combined_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-smell",
   "metadata": {},
   "source": [
    "### 4.3 Compare run times and memory usages on different machines\n",
    "All team members ran the above cell and recorded their memory usage and run time, see results below.  Note only `Wall time` is recorded below as `CPU time` was not available for all team members. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-strike",
   "metadata": {},
   "source": [
    "| User | Operating System | Memory | Time |\n",
    "|------|--------|--------|------|\n",
    "|Chirag| Ubuntu | 164.31 MiB, increment: 0.02 MiB| Wall  time: 5mins 4s|\n",
    "|Elanor| Windows| 91.42 MiB, increment: 0.28 MiB| Wall time: 6min 17s|\n",
    "| Hazel| Windows| 150.96MiB, increment: 0.06 MiB| Wall time: 6min 8s |\n",
    "| Siqi | MacOS  | 92.05 MiB, increment: 0.28 MiB| Wall time: 7min 40s|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-faculty",
   "metadata": {},
   "source": [
    "When combining CSV files, the team had range of memory usage of 92-152 MiB, and a range of run time of 6-9 mins across 3 different operating systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-agenda",
   "metadata": {},
   "source": [
    "## 5. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-simple",
   "metadata": {},
   "source": [
    "### 5.1.1 Loading in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hearing-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 6243.19 MiB, increment: 1459.53 MiB\n",
      "CPU times: user 52.1 s, sys: 3.86 s, total: 55.9 s\n",
      "Wall time: 57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figsharedailyrain/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-apache",
   "metadata": {},
   "source": [
    "### 5.1.2 DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-affiliate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 6736.11 MiB, increment: 1896.00 MiB\n",
      "CPU times: user 1min 20s, sys: 8.44 s, total: 1min 28s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "ddf = dd.read_csv(\"figsharedailyrain/combined_data.csv\")\n",
    "print(ddf[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-willow",
   "metadata": {},
   "source": [
    "### 5.2 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-windows",
   "metadata": {},
   "source": [
    "* We investigated two approaches,first using chunks and second using dask.\n",
    "* The first approach loads the combined csv file in chuncks of `10_000_000` and serially performs EDA of counting models\n",
    "* The second approach using dask internally loads in chunks and performs eda parallely in an optimized way.\n",
    "* The memory usage in both the first and second approach is similar. \n",
    "* The CPU time is higher in the dask approach as compared to first approach. Also there is higher difference between CPU time and Wall time in dask than first approach  \n",
    "* The wall time of second approach using dask is better than the first approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-volunteer",
   "metadata": {},
   "source": [
    "## 6. Perform a simple EDA in R\n",
    "\n",
    "Pick an approach to transfer the dataframe from python to R.\n",
    "* Parquet file\n",
    "* Feather file (We chose this one)\n",
    "* Pandas exchange\n",
    "* Arrow exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-serve",
   "metadata": {},
   "source": [
    "### Reasons to choose **feather**\n",
    "\n",
    "The team referred to lecture notes and online resources to compare the four approaches above and determined to choose **Feather** at the end as the best practice. The reasons are listed as follows,\n",
    "\n",
    "- **Feather** is faster than `parquet file` and `arrow exchange` when writing files since it store the data with lesser serialization and deserialization, leading to a higher I/O speed.\n",
    "- `parquet file` has the advantages of saving storage memory. However, it is more appropriate to choose **Feather** as this use case requests a faster speed than data storage.\n",
    "- **Feather** fits well with the R programming language since the API is embedded well for reading and writing data using R.\n",
    "- Team researched online articles to compare those four approaches according to experiments and benchmarking results. The team concluded **Feather** is the ideal choice. \n",
    "- **Feather** works well among Jupyter notebook sessions. It also speeds up the data queries without taking much memory on the disk, and there is no need for any unpacking when loaded the data back into RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-literacy",
   "metadata": {},
   "source": [
    "### 6.1 Use Feather to transfer the dataframe from Python to R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "maritime-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import rpy2.rinterface\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guided-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(arrow)\n",
    "library(dplyr)\n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesser-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 9589.81 MiB, increment: 4070.66 MiB\n",
      "CPU times: user 21.1 s, sys: 3.07 s, total: 24.1 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "dataset = ds.dataset(\"figsharedailyrain/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "earlier-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.49 s, sys: 973 ms, total: 5.46 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write in feather format\n",
    "feather.write_feather(table, 'figsharedailyrain/combined_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-alignment",
   "metadata": {},
   "source": [
    "### 6.2 Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collaborative-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "Time difference of 5.528802 secs\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "CPU times: user 7.06 s, sys: 4 s, total: 11.1 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "# Calculate how much time it took to read a feather file\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figsharedailyrain/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "\n",
    "# Print the different counts of the models \n",
    "result <- r_table %>% count(model) \n",
    "end_time <- Sys.time()\n",
    "\n",
    "print(end_time - start_time)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prospective-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 92,010 x 2\u001b[39m\n",
      "   time                    n\n",
      "   \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m 1888-12-31 \u001b[90m19:00:00\u001b[39m    28\n",
      "\u001b[90m 2\u001b[39m 1889-01-01 \u001b[90m07:00:00\u001b[39m  \u001b[4m1\u001b[24m330\n",
      "\u001b[90m 3\u001b[39m 1889-01-01 \u001b[90m19:00:00\u001b[39m    28\n",
      "\u001b[90m 4\u001b[39m 1889-01-02 \u001b[90m07:00:00\u001b[39m  \u001b[4m1\u001b[24m330\n",
      "\u001b[90m 5\u001b[39m 1889-01-02 \u001b[90m19:00:00\u001b[39m    28\n",
      "\u001b[90m 6\u001b[39m 1889-01-03 \u001b[90m07:00:00\u001b[39m  \u001b[4m1\u001b[24m330\n",
      "\u001b[90m 7\u001b[39m 1889-01-03 \u001b[90m19:00:00\u001b[39m    28\n",
      "\u001b[90m 8\u001b[39m 1889-01-04 \u001b[90m07:00:00\u001b[39m  \u001b[4m1\u001b[24m330\n",
      "\u001b[90m 9\u001b[39m 1889-01-04 \u001b[90m19:00:00\u001b[39m    28\n",
      "\u001b[90m10\u001b[39m 1889-01-05 \u001b[90m07:00:00\u001b[39m  \u001b[4m1\u001b[24m330\n",
      "\u001b[90m# … with 92,000 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# Print the different counts of the time\n",
    "result <- r_table %>% count(time) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-interim",
   "metadata": {},
   "source": [
    "### 6.3 Discussion\n",
    "\n",
    "When comparing the running time, it seems like using R is faster than the speed performed using Python. There is no difference in terms of the counts for models between the EDA results using Python and R. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-veteran",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "There are several challenges the team faced when dealing with large data sets. We can only perform limited and simple EDA with a local machine since large-scale data is very costly to visualize and calculate using complex matrics and evaluation. It is highly inconvenient to run every cell in the Jupyter notebook in our local machine as it would take a lot of time and consume majority of RAM leading to crashing of the kernel as well. Also, downloading and storing the huge files that is not optimised for processing would not be efficient in terms of time and computer resources.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
